{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a22f82f-8e89-4db5-8f34-45aeec8313cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from itertools import zip_longest  # Ensure this import is included\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd611c-f675-4fdd-bb5e-59014478f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize WebDriver\n",
    "options = Options()\n",
    "options.headless = True  # Run in headless mode (no browser window)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Lists to store the extracted data\n",
    "job_tit = []\n",
    "loc = []\n",
    "company_n = []\n",
    "job_exper = []\n",
    "\n",
    "def scrape_page(page_num):\n",
    "    url = f\"https://wuzzuf.net/search/jobs/?a=hpb&q=data%20engineer&start={page_num}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Wait for the page to fully load\n",
    "\n",
    "    # Extract job data from the page using Selenium\n",
    "    job_titles = driver.find_elements(By.CSS_SELECTOR, \"h2.css-m604qf\")\n",
    "    locations = driver.find_elements(By.CSS_SELECTOR, \"span.css-5wys0k\")\n",
    "    company_names = driver.find_elements(By.CSS_SELECTOR, \"a.css-17s97q8\")\n",
    "    job_experiences = driver.find_elements(By.CSS_SELECTOR, \"div.css-y4udm8\")\n",
    "\n",
    "    # Ensure all lists have the same length\n",
    "    min_length = min(len(job_titles), len(locations), len(company_names), len(job_experiences))\n",
    "    for i in range(min_length):\n",
    "        job_tit.append(job_titles[i].text.strip())\n",
    "        loc.append(locations[i].text.strip())\n",
    "        company_n.append(company_names[i].text.strip())\n",
    "        job_exper.append(job_experiences[i].text.strip())\n",
    "\n",
    "# Loop through pages and scrape data\n",
    "for page_num in range(0, 87):\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "    scrape_page(page_num)\n",
    "    time.sleep(2)  # Sleep for 2 seconds to avoid getting blocked\n",
    "\n",
    "# Export the data to a CSV file\n",
    "file_list = [job_tit, loc, company_n, job_exper]\n",
    "exported = zip_longest(*file_list)\n",
    "\n",
    "# Corrected file path with escaping or using a raw string\n",
    "try:\n",
    "    with open(r\"C:\\Users\\omarn\\Downloads\\data_engineer.csv\", \"w\", newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"job title\", \"location\", \"company name\", \"job experience\"])\n",
    "        writer.writerows(exported)\n",
    "    print(\"Data scraping completed and exported to data_engineer.csv.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while writing the file: {e}\")\n",
    "\n",
    "# Quit the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e941f-6fe8-4df1-a290-94defb79f9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example",
   "language": "python",
   "name": "example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
